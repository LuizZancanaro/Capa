{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Motivação\n",
        "Devido minha vontade de ingressar no mundo da ciência de dados percebi que o LinkedIn é uma ferramenta importante nessa jornada, e reparando nos perfis de outras pessoas percebi a necessidade de ter um perfil atraente, por isso pensei em fazer uma nuvem de palavras que representasse o meu perfil.\n",
        "\n",
        "Assim surgiu minha primeira pergunta: Quais palavras usar?"
      ],
      "metadata": {
        "id": "bY5jp0yuM9aC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Palavras\n",
        "A ideia de uma capa de perfil com uma nuvem de palavras fazia sentido, mas escolher palavras aleatórias não me representaria e não geraria valor para o meu perfil, por isso decidi usar os títulos dos certificados que eu já completei na Alura.\n",
        "\n",
        "Assim teria palavras que me representam e divulgam os meus estudos."
      ],
      "metadata": {
        "id": "9SyhQ4RvNrZO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Certificados\n",
        "Copiei e colei todos dos certificados que eu fiz em uma str, pode ser acessado pelo link: [Certificados Alura Zancanaro](https://cursos.alura.com.br/user/Luiz-zan/fullCertificate/6bccb403285c3e0cc05e809f3712af96)"
      ],
      "metadata": {
        "id": "vMlBT8yrPPYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "certificados ='''\n",
        "Formações:\n",
        "Ocultar Formação\n",
        "Formação: Excel - 58hs\n",
        "Cursos:\n",
        "Excel: domine o editor de planilhas (de 21/02/2023 a 16/03/2023) 10hrs\n",
        "Funções com Excel: operações matemáticas e filtros (de 18/05/2023 a 25/05/2023) 10hrs\n",
        "Excel procv: lógica booleana e busca por valores (de 23/05/2023 a 27/05/2023) 12hrs\n",
        "Excel: tabelas dinâmicas e dashboards (de 27/05/2023 a 29/05/2023) 10hrs\n",
        "Excel: simulação e análise de cenários (de 12/06/2023 a 22/06/2023) 6hrs\n",
        "Análise de dados: cálculos, padrões e estratégias com Excel (de 23/06/2023 a 26/06/2023) 6hrs\n",
        "Conteúdos complementares:\n",
        "Alura+: PROCV no Excel para valores repetidos - 8min\n",
        "Alura+: Excel: Entendendo a função PROCX - 12min\n",
        "Video: Como o Excel pode te ajudar no dia a dia - YouTube - 60min\n",
        "Artigo: Função PROCX | Alura Cursos Online - 30min\n",
        "Video: Fazendo mágica com Excel - 60min\n",
        "Artigo: Média ponderada no Excel | Alura Cursos Online - 30min\n",
        "Ocultar Formação\n",
        "Formação: Data Analysis com Google Sheets - 35hs\n",
        "Cursos:\n",
        "Data Analysis: Google Sheets (de 20/12/2022 a 02/01/2023) 6hrs\n",
        "Data Analysis: previsões com Google Sheets (de 17/07/2023 a 19/07/2023) 8hrs\n",
        "Data Analysis: estatística com Google Sheets (de 21/02/2023 a 24/02/2023) 8hrs\n",
        "Data Visualization: técnicas de visualização com Google Sheets (de 19/07/2023 a 23/07/2023) 8hrs\n",
        "Conteúdos complementares:\n",
        "Alura+: Testes estatísticos com Google Sheets - 8min\n",
        "Alura+: Google Sheets: Testes estatísticos para duas amostras - 7min\n",
        "Alura+: Data Visualization: Técnicas aplicadas no gráfico de linhas - 15min\n",
        "Hipsters: Primeiros Passos em Data Science: Do Excel e BI ao Python – Hipsters #134 - 60min\n",
        "Video: Vídeo de introdução à Formação Data Analysis com Google Sheets - YouTube - 60min\n",
        "Artigo: Google Sheets ou Microsoft Excel: qual ferramenta escolher? | Alura Cursos Online - 30min\n",
        "Artigo: Séries temporais: Tipos de sazonalidade | Alura Cursos Online - 30min\n",
        "Artigo: O que é um histograma? | Alura Cursos Online - 30min\n",
        "Video: Vídeo de conclusão da Formação Data Analysis com Google Sheets - YouTube - 60min\n",
        "Ocultar Formação\n",
        "Formação: Python para Data Science - 69hs\n",
        "Cursos:\n",
        "Python para Data Science (de 22/11/2022 a 22/11/2022) 10hrs\n",
        "Python para Data Science: linguagem e Numpy (de 23/11/2022 a 24/11/2022) 12hrs\n",
        "Python para Data Science: Funções, Pacotes e Pandas (de 25/11/2022 a 28/11/2022) 10hrs\n",
        "Python Pandas: tratando e analisando dados (de 28/11/2022 a 03/12/2022) 12hrs\n",
        "Data Visualization: explorando com Seaborn (de 22/12/2022 a 01/01/2023) 6hrs\n",
        "Data Science: análise de series temporais (de 22/12/2022 a 01/01/2023) 6hrs\n",
        "Corretor Ortográfico em Python: aplicando técnicas de NLP (de 06/02/2023 a 21/02/2023) 10hrs\n",
        "Conteúdos complementares:\n",
        "Hipsters: Data Science e Política na Operação Serenata de Amor – Hipsters #62 - 38min\n",
        "Hipsters: Machine Learning – Hipsters #89 - 47min\n",
        "Hipsters: Big Data e Data Science: pra quê afinal? – Hipsters #73 - 35min\n",
        "Video: O que é Data Science? #HipstersPontoTube - YouTube - 60min\n",
        "Cursos:\n",
        "Data Science - 98hs\n",
        "Data Analysis: introdução a séries temporais e análises (de 26/03/2023 a 02/04/2023) 8hrs\n",
        "Regressão linear: testando relações e prevendo resultados (de 02/04/2023 a 26/05/2023) 12hrs\n",
        "Pandas: formatos diferentes de entrada e saída (IO) (de 28/11/2022 a 10/12/2022) 6hrs\n",
        "Estatística com Python: frequências e medidas (de 10/12/2022 a 02/01/2023) 10hrs\n",
        "Estatística com Python: probabilidade e amostragem (de 02/01/2023 a 21/02/2023) 10hrs\n",
        "Estatística com Python: testes de hipóteses (de 06/08/2023 a 17/08/2023) 10hrs\n",
        "Spark: apresentando a ferramenta (de 05/12/2022 a 12/12/2022) 10hrs\n",
        "Power BI: modelagem de dados (de 09/03/2023 a 23/03/2023) 8hrs\n",
        "Python para Data Science: primeiros passos (de 27/06/2023 a 16/07/2023) 10hrs\n",
        "Python para Data Science: funções, estruturas de dados e exceções (de 28/08/2023 a 31/08/2023) 8hrs\n",
        "Python: análise de dados com SQL (de 19/07/2023 a 02/08/2023) 6hrs\n",
        "Inovação & Gestão - 8hs\n",
        "Aprender a aprender: técnicas para seu autodesenvolvimento (de 13/05/2023 a 25/05/2023) 8hrs'''"
      ],
      "metadata": {
        "id": "x-yNabwzNrBI"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Limpando a Str\n",
        "Vamos começar remover algumas pontuações e algumas as quebras de linha."
      ],
      "metadata": {
        "id": "g4NopFWSP-nu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sem_simbolos = ''\n",
        "\n",
        "for i in range(len(certificados)):\n",
        "  if certificados[i] != '(' and certificados[i] != ':' and certificados[i] != '-' and certificados[i] != ')' and certificados[i] != '.' and certificados[i] != '/'and certificados[i] != '|' and certificados[i] != '?' and certificados[i] != '#':\n",
        "    sem_simbolos += certificados[i]"
      ],
      "metadata": {
        "id": "9RR1j51dUhRp"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sem_simbolos #Como os \\n estão ligando algumas palavras eu não posso simplemente remover."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "grGWPPkqcXAT",
        "outputId": "98be384b-6834-4450-f4f3-98ba5db40119"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nFormações\\nOcultar Formação\\nFormação Excel  58hs\\nCursos\\nExcel domine o editor de planilhas de 21022023 a 16032023 10hrs\\nFunções com Excel operações matemáticas e filtros de 18052023 a 25052023 10hrs\\nExcel procv lógica booleana e busca por valores de 23052023 a 27052023 12hrs\\nExcel tabelas dinâmicas e dashboards de 27052023 a 29052023 10hrs\\nExcel simulação e análise de cenários de 12062023 a 22062023 6hrs\\nAnálise de dados cálculos, padrões e estratégias com Excel de 23062023 a 26062023 6hrs\\nConteúdos complementares\\nAlura+ PROCV no Excel para valores repetidos  8min\\nAlura+ Excel Entendendo a função PROCX  12min\\nVideo Como o Excel pode te ajudar no dia a dia  YouTube  60min\\nArtigo Função PROCX  Alura Cursos Online  30min\\nVideo Fazendo mágica com Excel  60min\\nArtigo Média ponderada no Excel  Alura Cursos Online  30min\\nOcultar Formação\\nFormação Data Analysis com Google Sheets  35hs\\nCursos\\nData Analysis Google Sheets de 20122022 a 02012023 6hrs\\nData Analysis previsões com Google Sheets de 17072023 a 19072023 8hrs\\nData Analysis estatística com Google Sheets de 21022023 a 24022023 8hrs\\nData Visualization técnicas de visualização com Google Sheets de 19072023 a 23072023 8hrs\\nConteúdos complementares\\nAlura+ Testes estatísticos com Google Sheets  8min\\nAlura+ Google Sheets Testes estatísticos para duas amostras  7min\\nAlura+ Data Visualization Técnicas aplicadas no gráfico de linhas  15min\\nHipsters Primeiros Passos em Data Science Do Excel e BI ao Python – Hipsters 134  60min\\nVideo Vídeo de introdução à Formação Data Analysis com Google Sheets  YouTube  60min\\nArtigo Google Sheets ou Microsoft Excel qual ferramenta escolher  Alura Cursos Online  30min\\nArtigo Séries temporais Tipos de sazonalidade  Alura Cursos Online  30min\\nArtigo O que é um histograma  Alura Cursos Online  30min\\nVideo Vídeo de conclusão da Formação Data Analysis com Google Sheets  YouTube  60min\\nOcultar Formação\\nFormação Python para Data Science  69hs\\nCursos\\nPython para Data Science de 22112022 a 22112022 10hrs\\nPython para Data Science linguagem e Numpy de 23112022 a 24112022 12hrs\\nPython para Data Science Funções, Pacotes e Pandas de 25112022 a 28112022 10hrs\\nPython Pandas tratando e analisando dados de 28112022 a 03122022 12hrs\\nData Visualization explorando com Seaborn de 22122022 a 01012023 6hrs\\nData Science análise de series temporais de 22122022 a 01012023 6hrs\\nCorretor Ortográfico em Python aplicando técnicas de NLP de 06022023 a 21022023 10hrs\\nConteúdos complementares\\nHipsters Data Science e Política na Operação Serenata de Amor – Hipsters 62  38min\\nHipsters Machine Learning – Hipsters 89  47min\\nHipsters Big Data e Data Science pra quê afinal – Hipsters 73  35min\\nVideo O que é Data Science HipstersPontoTube  YouTube  60min\\nCursos\\nData Science  98hs\\nData Analysis introdução a séries temporais e análises de 26032023 a 02042023 8hrs\\nRegressão linear testando relações e prevendo resultados de 02042023 a 26052023 12hrs\\nPandas formatos diferentes de entrada e saída IO de 28112022 a 10122022 6hrs\\nEstatística com Python frequências e medidas de 10122022 a 02012023 10hrs\\nEstatística com Python probabilidade e amostragem de 02012023 a 21022023 10hrs\\nEstatística com Python testes de hipóteses de 06082023 a 17082023 10hrs\\nSpark apresentando a ferramenta de 05122022 a 12122022 10hrs\\nPower BI modelagem de dados de 09032023 a 23032023 8hrs\\nPython para Data Science primeiros passos de 27062023 a 16072023 10hrs\\nPython para Data Science funções, estruturas de dados e exceções de 28082023 a 31082023 8hrs\\nPython análise de dados com SQL de 19072023 a 02082023 6hrs\\nInovação & Gestão  8hs\\nAprender a aprender técnicas para seu autodesenvolvimento de 13052023 a 25052023 8hrs'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Trocando so '\\n' por espaço\n",
        "Logo no começo da str temos ``` \\nFormações\\nOcultar```. se eu tivesse removido o '\\n' ficaria com ```FormaçõesOcultar```. Por isso escolhi trocar os '\\n' por ' ', no caso espaços vazios.  \n"
      ],
      "metadata": {
        "id": "T3M3oxGsS-pE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "zBHvcA5LM3t0",
        "outputId": "f9deb1da-84e7-49f8-befb-2fbe86bea7a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Formações Ocultar Formação Formação Excel  58hs Cursos Excel domine o editor de planilhas de 21022023 a 16032023 10hrs Funções com Excel operações matemáticas e filtros de 18052023 a 25052023 10hrs Excel procv lógica booleana e busca por valores de 23052023 a 27052023 12hrs Excel tabelas dinâmicas e dashboards de 27052023 a 29052023 10hrs Excel simulação e análise de cenários de 12062023 a 22062023 6hrs Análise de dados cálculos, padrões e estratégias com Excel de 23062023 a 26062023 6hrs Conteúdos complementares Alura+ PROCV no Excel para valores repetidos  8min Alura+ Excel Entendendo a função PROCX  12min Video Como o Excel pode te ajudar no dia a dia  YouTube  60min Artigo Função PROCX  Alura Cursos Online  30min Video Fazendo mágica com Excel  60min Artigo Média ponderada no Excel  Alura Cursos Online  30min Ocultar Formação Formação Data Analysis com Google Sheets  35hs Cursos Data Analysis Google Sheets de 20122022 a 02012023 6hrs Data Analysis previsões com Google Sheets de 17072023 a 19072023 8hrs Data Analysis estatística com Google Sheets de 21022023 a 24022023 8hrs Data Visualization técnicas de visualização com Google Sheets de 19072023 a 23072023 8hrs Conteúdos complementares Alura+ Testes estatísticos com Google Sheets  8min Alura+ Google Sheets Testes estatísticos para duas amostras  7min Alura+ Data Visualization Técnicas aplicadas no gráfico de linhas  15min Hipsters Primeiros Passos em Data Science Do Excel e BI ao Python – Hipsters 134  60min Video Vídeo de introdução à Formação Data Analysis com Google Sheets  YouTube  60min Artigo Google Sheets ou Microsoft Excel qual ferramenta escolher  Alura Cursos Online  30min Artigo Séries temporais Tipos de sazonalidade  Alura Cursos Online  30min Artigo O que é um histograma  Alura Cursos Online  30min Video Vídeo de conclusão da Formação Data Analysis com Google Sheets  YouTube  60min Ocultar Formação Formação Python para Data Science  69hs Cursos Python para Data Science de 22112022 a 22112022 10hrs Python para Data Science linguagem e Numpy de 23112022 a 24112022 12hrs Python para Data Science Funções, Pacotes e Pandas de 25112022 a 28112022 10hrs Python Pandas tratando e analisando dados de 28112022 a 03122022 12hrs Data Visualization explorando com Seaborn de 22122022 a 01012023 6hrs Data Science análise de series temporais de 22122022 a 01012023 6hrs Corretor Ortográfico em Python aplicando técnicas de NLP de 06022023 a 21022023 10hrs Conteúdos complementares Hipsters Data Science e Política na Operação Serenata de Amor – Hipsters 62  38min Hipsters Machine Learning – Hipsters 89  47min Hipsters Big Data e Data Science pra quê afinal – Hipsters 73  35min Video O que é Data Science HipstersPontoTube  YouTube  60min Cursos Data Science  98hs Data Analysis introdução a séries temporais e análises de 26032023 a 02042023 8hrs Regressão linear testando relações e prevendo resultados de 02042023 a 26052023 12hrs Pandas formatos diferentes de entrada e saída IO de 28112022 a 10122022 6hrs Estatística com Python frequências e medidas de 10122022 a 02012023 10hrs Estatística com Python probabilidade e amostragem de 02012023 a 21022023 10hrs Estatística com Python testes de hipóteses de 06082023 a 17082023 10hrs Spark apresentando a ferramenta de 05122022 a 12122022 10hrs Power BI modelagem de dados de 09032023 a 23032023 8hrs Python para Data Science primeiros passos de 27062023 a 16072023 10hrs Python para Data Science funções, estruturas de dados e exceções de 28082023 a 31082023 8hrs Python análise de dados com SQL de 19072023 a 02082023 6hrs Inovação & Gestão  8hs Aprender a aprender técnicas para seu autodesenvolvimento de 13052023 a 25052023 8hrs'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 133
        }
      ],
      "source": [
        "sem_simbolos = sem_simbolos.replace('\\n', \" \")\n",
        "sem_simbolos"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Alguns Casos especiais\n",
        "Existem palavras como Data Science, que fazem mais sentido quando estão juntas, por isso eu dedici colocar um _ no lugar do espaço entre elas."
      ],
      "metadata": {
        "id": "Q4uWawW5VEwv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sem_simbolos = sem_simbolos.replace('Data Science', \"Data_Science\")\n",
        "sem_simbolos = sem_simbolos.replace('Google Sheets', \"Google_Sheets\")\n",
        "sem_simbolos = sem_simbolos.replace('Data Visualization', \"Data_Visualization\")\n",
        "sem_simbolos = sem_simbolos.replace('Data Analysis', \"Data_Analysis\")\n",
        "sem_simbolos = sem_simbolos.replace('BI', \"POWER_BI\")\n",
        "sem_simbolos = sem_simbolos.replace('POWER BI\")', \"POWER_BI\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Psgon8ekVgAG"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Separando as palavras\n",
        "Minha ideia foi usar os espaços para dizer onde começa e termina cada palavra."
      ],
      "metadata": {
        "id": "uVk8Z1QNhZmm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Achando os espaços"
      ],
      "metadata": {
        "id": "iRfDFqdsMiba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sem_simbolos = sem_simbolos + \" \" #Adicionei esse espaço no final da str para que eu garanta que a ultíma palavra não fique de fora.\n",
        "\n",
        "#Vou criar uma lista para achar a posição de cada espaço vazio na minha str\n",
        "\n",
        "espacos = []\n",
        "\n",
        "def acha_espaco(lista, str):\n",
        "  for i in range(len(str)):\n",
        "    if str[i] == ' ':\n",
        "      lista.append(i)\n",
        "\n",
        "  return lista\n",
        "\n",
        "\n",
        "\n",
        "acha_espaco(espacos, sem_simbolos)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHqnj_XAhYvL",
        "outputId": "f6a31f20-8a98-4749-d66d-d1392eb19373"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 10,\n",
              " 18,\n",
              " 27,\n",
              " 36,\n",
              " 42,\n",
              " 43,\n",
              " 48,\n",
              " 55,\n",
              " 61,\n",
              " 68,\n",
              " 70,\n",
              " 77,\n",
              " 80,\n",
              " 90,\n",
              " 93,\n",
              " 102,\n",
              " 104,\n",
              " 113,\n",
              " 119,\n",
              " 127,\n",
              " 131,\n",
              " 137,\n",
              " 147,\n",
              " 159,\n",
              " 161,\n",
              " 169,\n",
              " 172,\n",
              " 181,\n",
              " 183,\n",
              " 192,\n",
              " 198,\n",
              " 204,\n",
              " 210,\n",
              " 217,\n",
              " 226,\n",
              " 228,\n",
              " 234,\n",
              " 238,\n",
              " 246,\n",
              " 249,\n",
              " 258,\n",
              " 260,\n",
              " 269,\n",
              " 275,\n",
              " 281,\n",
              " 289,\n",
              " 299,\n",
              " 301,\n",
              " 312,\n",
              " 315,\n",
              " 324,\n",
              " 326,\n",
              " 335,\n",
              " 341,\n",
              " 347,\n",
              " 357,\n",
              " 359,\n",
              " 367,\n",
              " 370,\n",
              " 379,\n",
              " 382,\n",
              " 391,\n",
              " 393,\n",
              " 402,\n",
              " 407,\n",
              " 415,\n",
              " 418,\n",
              " 424,\n",
              " 434,\n",
              " 442,\n",
              " 444,\n",
              " 456,\n",
              " 460,\n",
              " 466,\n",
              " 469,\n",
              " 478,\n",
              " 480,\n",
              " 489,\n",
              " 494,\n",
              " 504,\n",
              " 519,\n",
              " 526,\n",
              " 532,\n",
              " 535,\n",
              " 541,\n",
              " 546,\n",
              " 554,\n",
              " 564,\n",
              " 565,\n",
              " 570,\n",
              " 577,\n",
              " 583,\n",
              " 594,\n",
              " 596,\n",
              " 603,\n",
              " 609,\n",
              " 610,\n",
              " 616,\n",
              " 622,\n",
              " 627,\n",
              " 629,\n",
              " 635,\n",
              " 640,\n",
              " 643,\n",
              " 650,\n",
              " 653,\n",
              " 657,\n",
              " 659,\n",
              " 663,\n",
              " 664,\n",
              " 672,\n",
              " 673,\n",
              " 679,\n",
              " 686,\n",
              " 693,\n",
              " 699,\n",
              " 700,\n",
              " 706,\n",
              " 713,\n",
              " 720,\n",
              " 721,\n",
              " 727,\n",
              " 733,\n",
              " 741,\n",
              " 748,\n",
              " 752,\n",
              " 758,\n",
              " 759,\n",
              " 765,\n",
              " 772,\n",
              " 778,\n",
              " 788,\n",
              " 791,\n",
              " 797,\n",
              " 798,\n",
              " 804,\n",
              " 811,\n",
              " 818,\n",
              " 819,\n",
              " 825,\n",
              " 833,\n",
              " 842,\n",
              " 851,\n",
              " 865,\n",
              " 869,\n",
              " 883,\n",
              " 884,\n",
              " 889,\n",
              " 896,\n",
              " 910,\n",
              " 924,\n",
              " 927,\n",
              " 936,\n",
              " 938,\n",
              " 947,\n",
              " 952,\n",
              " 966,\n",
              " 976,\n",
              " 980,\n",
              " 994,\n",
              " 997,\n",
              " 1006,\n",
              " 1008,\n",
              " 1017,\n",
              " 1022,\n",
              " 1036,\n",
              " 1048,\n",
              " 1052,\n",
              " 1066,\n",
              " 1069,\n",
              " 1078,\n",
              " 1080,\n",
              " 1089,\n",
              " 1094,\n",
              " 1113,\n",
              " 1122,\n",
              " 1125,\n",
              " 1138,\n",
              " 1142,\n",
              " 1156,\n",
              " 1159,\n",
              " 1168,\n",
              " 1170,\n",
              " 1179,\n",
              " 1184,\n",
              " 1194,\n",
              " 1209,\n",
              " 1216,\n",
              " 1223,\n",
              " 1236,\n",
              " 1240,\n",
              " 1254,\n",
              " 1255,\n",
              " 1260,\n",
              " 1267,\n",
              " 1281,\n",
              " 1288,\n",
              " 1301,\n",
              " 1306,\n",
              " 1311,\n",
              " 1320,\n",
              " 1321,\n",
              " 1326,\n",
              " 1333,\n",
              " 1352,\n",
              " 1361,\n",
              " 1371,\n",
              " 1374,\n",
              " 1382,\n",
              " 1385,\n",
              " 1392,\n",
              " 1393,\n",
              " 1399,\n",
              " 1408,\n",
              " 1418,\n",
              " 1425,\n",
              " 1428,\n",
              " 1441,\n",
              " 1444,\n",
              " 1450,\n",
              " 1452,\n",
              " 1461,\n",
              " 1464,\n",
              " 1471,\n",
              " 1473,\n",
              " 1482,\n",
              " 1486,\n",
              " 1487,\n",
              " 1493,\n",
              " 1499,\n",
              " 1505,\n",
              " 1508,\n",
              " 1519,\n",
              " 1521,\n",
              " 1530,\n",
              " 1544,\n",
              " 1548,\n",
              " 1562,\n",
              " 1563,\n",
              " 1571,\n",
              " 1572,\n",
              " 1578,\n",
              " 1585,\n",
              " 1599,\n",
              " 1602,\n",
              " 1612,\n",
              " 1618,\n",
              " 1623,\n",
              " 1634,\n",
              " 1643,\n",
              " 1644,\n",
              " 1650,\n",
              " 1657,\n",
              " 1664,\n",
              " 1665,\n",
              " 1671,\n",
              " 1678,\n",
              " 1685,\n",
              " 1695,\n",
              " 1701,\n",
              " 1704,\n",
              " 1717,\n",
              " 1718,\n",
              " 1724,\n",
              " 1731,\n",
              " 1738,\n",
              " 1739,\n",
              " 1745,\n",
              " 1752,\n",
              " 1754,\n",
              " 1758,\n",
              " 1760,\n",
              " 1763,\n",
              " 1774,\n",
              " 1775,\n",
              " 1781,\n",
              " 1788,\n",
              " 1795,\n",
              " 1796,\n",
              " 1802,\n",
              " 1808,\n",
              " 1814,\n",
              " 1817,\n",
              " 1827,\n",
              " 1830,\n",
              " 1839,\n",
              " 1853,\n",
              " 1857,\n",
              " 1871,\n",
              " 1872,\n",
              " 1880,\n",
              " 1881,\n",
              " 1887,\n",
              " 1895,\n",
              " 1904,\n",
              " 1913,\n",
              " 1920,\n",
              " 1925,\n",
              " 1938,\n",
              " 1939,\n",
              " 1944,\n",
              " 1951,\n",
              " 1958,\n",
              " 1963,\n",
              " 1976,\n",
              " 1979,\n",
              " 1988,\n",
              " 1990,\n",
              " 1999,\n",
              " 2005,\n",
              " 2012,\n",
              " 2017,\n",
              " 2030,\n",
              " 2040,\n",
              " 2042,\n",
              " 2048,\n",
              " 2051,\n",
              " 2060,\n",
              " 2062,\n",
              " 2071,\n",
              " 2077,\n",
              " 2084,\n",
              " 2089,\n",
              " 2102,\n",
              " 2111,\n",
              " 2119,\n",
              " 2121,\n",
              " 2128,\n",
              " 2131,\n",
              " 2140,\n",
              " 2142,\n",
              " 2151,\n",
              " 2157,\n",
              " 2164,\n",
              " 2171,\n",
              " 2180,\n",
              " 2182,\n",
              " 2193,\n",
              " 2199,\n",
              " 2202,\n",
              " 2211,\n",
              " 2213,\n",
              " 2222,\n",
              " 2228,\n",
              " 2247,\n",
              " 2258,\n",
              " 2262,\n",
              " 2270,\n",
              " 2273,\n",
              " 2282,\n",
              " 2284,\n",
              " 2293,\n",
              " 2298,\n",
              " 2311,\n",
              " 2319,\n",
              " 2322,\n",
              " 2329,\n",
              " 2339,\n",
              " 2342,\n",
              " 2351,\n",
              " 2353,\n",
              " 2362,\n",
              " 2367,\n",
              " 2376,\n",
              " 2388,\n",
              " 2391,\n",
              " 2398,\n",
              " 2408,\n",
              " 2417,\n",
              " 2420,\n",
              " 2424,\n",
              " 2427,\n",
              " 2436,\n",
              " 2438,\n",
              " 2447,\n",
              " 2453,\n",
              " 2463,\n",
              " 2478,\n",
              " 2487,\n",
              " 2500,\n",
              " 2502,\n",
              " 2511,\n",
              " 2514,\n",
              " 2523,\n",
              " 2532,\n",
              " 2535,\n",
              " 2540,\n",
              " 2542,\n",
              " 2551,\n",
              " 2554,\n",
              " 2555,\n",
              " 2561,\n",
              " 2570,\n",
              " 2578,\n",
              " 2587,\n",
              " 2589,\n",
              " 2598,\n",
              " 2601,\n",
              " 2602,\n",
              " 2608,\n",
              " 2617,\n",
              " 2621,\n",
              " 2626,\n",
              " 2628,\n",
              " 2641,\n",
              " 2645,\n",
              " 2649,\n",
              " 2656,\n",
              " 2658,\n",
              " 2667,\n",
              " 2670,\n",
              " 2671,\n",
              " 2677,\n",
              " 2683,\n",
              " 2685,\n",
              " 2689,\n",
              " 2691,\n",
              " 2704,\n",
              " 2722,\n",
              " 2723,\n",
              " 2731,\n",
              " 2732,\n",
              " 2738,\n",
              " 2745,\n",
              " 2758,\n",
              " 2759,\n",
              " 2764,\n",
              " 2778,\n",
              " 2789,\n",
              " 2791,\n",
              " 2798,\n",
              " 2808,\n",
              " 2810,\n",
              " 2819,\n",
              " 2822,\n",
              " 2831,\n",
              " 2833,\n",
              " 2842,\n",
              " 2847,\n",
              " 2857,\n",
              " 2864,\n",
              " 2873,\n",
              " 2882,\n",
              " 2884,\n",
              " 2893,\n",
              " 2904,\n",
              " 2907,\n",
              " 2916,\n",
              " 2918,\n",
              " 2927,\n",
              " 2933,\n",
              " 2940,\n",
              " 2949,\n",
              " 2960,\n",
              " 2963,\n",
              " 2971,\n",
              " 2973,\n",
              " 2979,\n",
              " 2982,\n",
              " 2985,\n",
              " 2994,\n",
              " 2996,\n",
              " 3005,\n",
              " 3010,\n",
              " 3022,\n",
              " 3026,\n",
              " 3033,\n",
              " 3045,\n",
              " 3047,\n",
              " 3055,\n",
              " 3058,\n",
              " 3067,\n",
              " 3069,\n",
              " 3078,\n",
              " 3084,\n",
              " 3096,\n",
              " 3100,\n",
              " 3107,\n",
              " 3121,\n",
              " 3123,\n",
              " 3134,\n",
              " 3137,\n",
              " 3146,\n",
              " 3148,\n",
              " 3157,\n",
              " 3163,\n",
              " 3175,\n",
              " 3179,\n",
              " 3186,\n",
              " 3193,\n",
              " 3196,\n",
              " 3206,\n",
              " 3209,\n",
              " 3218,\n",
              " 3220,\n",
              " 3229,\n",
              " 3235,\n",
              " 3241,\n",
              " 3254,\n",
              " 3256,\n",
              " 3267,\n",
              " 3270,\n",
              " 3279,\n",
              " 3281,\n",
              " 3290,\n",
              " 3296,\n",
              " 3302,\n",
              " 3311,\n",
              " 3321,\n",
              " 3324,\n",
              " 3330,\n",
              " 3333,\n",
              " 3342,\n",
              " 3344,\n",
              " 3353,\n",
              " 3358,\n",
              " 3365,\n",
              " 3370,\n",
              " 3383,\n",
              " 3393,\n",
              " 3400,\n",
              " 3403,\n",
              " 3412,\n",
              " 3414,\n",
              " 3423,\n",
              " 3429,\n",
              " 3436,\n",
              " 3441,\n",
              " 3454,\n",
              " 3463,\n",
              " 3474,\n",
              " 3477,\n",
              " 3483,\n",
              " 3485,\n",
              " 3494,\n",
              " 3497,\n",
              " 3506,\n",
              " 3508,\n",
              " 3517,\n",
              " 3522,\n",
              " 3529,\n",
              " 3537,\n",
              " 3540,\n",
              " 3546,\n",
              " 3550,\n",
              " 3554,\n",
              " 3557,\n",
              " 3566,\n",
              " 3568,\n",
              " 3577,\n",
              " 3582,\n",
              " 3591,\n",
              " 3593,\n",
              " 3600,\n",
              " 3601,\n",
              " 3605,\n",
              " 3614,\n",
              " 3616,\n",
              " 3625,\n",
              " 3634,\n",
              " 3639,\n",
              " 3643,\n",
              " 3663,\n",
              " 3666,\n",
              " 3675,\n",
              " 3677,\n",
              " 3686,\n",
              " 3691]"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Separando as palavras em uma lista"
      ],
      "metadata": {
        "id": "Xg8Wx5OrMbI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def separa_palavra(lista_espaco, lista_separada, str):                            # A função recebe 3 parametros, a lista com os espaços, a lista que vai guardar as palavas, e a str com todas as palavras\n",
        "  for i in range(len(lista_espaco) -1):                                           # Passa por todos os elementos da lista com os espaços menos o úlitmo\n",
        "    if int(lista_espaco[i+1]) - int(lista_espaco[i]) >=5:                         # Verifica se a diferença entre dois elementos é maior ou igual que 4, isso vai servir para só pegar palavras com  mais 4 letras\n",
        "       lista_separada.append(str[lista_espaco[i]+1:lista_espaco[i+1]].lower())    # Salva as palavras com mais de 4 letras\n",
        "\n",
        "  return lista_separada                                                           # Mostra lista de palavras"
      ],
      "metadata": {
        "id": "7h17lcJ6Mydj"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "palavras_separadas = []\n",
        "\n",
        "separa_palavra(espacos, palavras_separadas, sem_simbolos)"
      ],
      "metadata": {
        "id": "FYNGaRTTNxpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Separando as palavras"
      ],
      "metadata": {
        "id": "HukAeH9XPnrk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unica(repetidas, unicas):                    # Criando a função para remover as repetições\n",
        "  contador = 0                                   # Variável para garantir a unicidade\n",
        "  for i in range(len(repetidas)):                # Passando por cada uma das as palavras\n",
        "    for k in range(len(unicas)):                 # Passando por cada uma das palavras já separadas\n",
        "      if repetidas[i] == unicas[k]:              # Verificando se a palavra separada existe na lista de palavras\n",
        "        contador = contador + 1                  # Quantidade de vezes que ela existe\n",
        "    if contador == 0:                            # Se ela não foi contada nenhuma vez\n",
        "      unicas.append(repetidas[i])                # Adiciona ela na lista\n",
        "      contador = 0                               # Zera o contador para a proxima palavra\n",
        "    else:\n",
        "      contador = 0                               # Não adiciona a palavra, mas zera o contador para próxima palavra\n",
        "\n",
        "  return unicas                                  # Mostra as palavras"
      ],
      "metadata": {
        "id": "XUKlbqHFPs_c"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sem_repeticao = []\n",
        "unica(palavras_separadas, sem_repeticao)"
      ],
      "metadata": {
        "id": "U2tB9IVIQmas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sem_repeticao)\n"
      ],
      "metadata": {
        "id": "eRl4ypsCTH_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Contando as palavras"
      ],
      "metadata": {
        "id": "hPNJYdk9YMld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def contador(lista_unicas, lista, dicionario):    # Criando a função que vai contar as palavras\n",
        "  contador = 0                                    # Variável não global que vai auxiliar\n",
        "  for palavras_unicas in lista_unicas:            # Passando por cada palavra única\n",
        "    contador = lista.count(palavras_unicas)       # Fazendo a contagem de cada palavra na lista com todas as palavras\n",
        "    dicionario[palavras_unicas] = contador        # Criando um dicionário para armazenar as palavras e a quantidade de vezes que ela aparece\n",
        "    contador = 0\n",
        "\n",
        "  return dicionario"
      ],
      "metadata": {
        "id": "_T8V7F_MYQlf"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "palavras_contadas ={}\n",
        "\n",
        "contador(sem_repeticao, palavras_separadas, palavras_contadas)"
      ],
      "metadata": {
        "id": "bM6xtesiZXYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Selecionando as palavras importantes\n",
        "Muitas palavras só aparecem 1 ou 2 vezes, essas não fazem sentido estarem na minha nuvem de palavras, eu vou querer somente as palavras que aparecem 3 ou mais vezes.\n",
        "Percebido que existiam palavras que não estão fazendo sentido mas como elas devem aparecer poucas vezes preferi deixa-las e remove-las agora em uma filtragem final."
      ],
      "metadata": {
        "id": "EhIGUqX5Zv1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def selecionador(dicionario):          # Criando a função que vai receber o dicionário\n",
        "  for item in dicionario:              # Passando por cada elemento do dicionário\n",
        "    if int(dicionario[item]) >= 3:     # Verificando a quantidade de cada elemento\n",
        "      print(item, dicionario[item])    # Imprimindo a palavra e a quantidade de vezes que ela aparece\n",
        "\n",
        "  return"
      ],
      "metadata": {
        "id": "jAlCt4i5aYTx"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selecionador(palavras_contadas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_M7iKfV6b8jw",
        "outputId": "d222810e-f0ae-4e47-d292-5d2c03355697"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ocultar 3\n",
            "formação 8\n",
            "excel 14\n",
            "cursos 9\n",
            "21022023 4\n",
            "10hrs 11\n",
            "12hrs 4\n",
            "análise 4\n",
            "6hrs 7\n",
            "dados 5\n",
            "conteúdos 3\n",
            "complementares 3\n",
            "alura+ 5\n",
            "para 9\n",
            "video 5\n",
            "youtube 4\n",
            "60min 6\n",
            "artigo 5\n",
            "alura 5\n",
            "online 5\n",
            "30min 5\n",
            "data_analysis 7\n",
            "google_sheets 10\n",
            "02012023 3\n",
            "19072023 3\n",
            "8hrs 7\n",
            "estatística 4\n",
            "data_visualization 3\n",
            "técnicas 4\n",
            "testes 3\n",
            "hipsters 8\n",
            "data_science 12\n",
            "python 13\n",
            "temporais 3\n",
            "pandas 3\n",
            "28112022 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Depois disso removi mais algumas palavras, adaptei outras e finalmente consegui monta a nuvem de palavras.\n",
        "\n",
        "[nuvem de palavras](https://media.licdn.com/dms/image/D5616AQGcKMvFF5GBHA/profile-displaybackgroundimage-shrink_350_1400/0/1691075297808?e=1698883200&v=beta&t=_TaiwfadBFfIeAiMTcOpyRzzsZrIYWh6JrdEoi9CfPc)"
      ],
      "metadata": {
        "id": "ucdi5GgHhmhZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9KBnxpXNhmSD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}